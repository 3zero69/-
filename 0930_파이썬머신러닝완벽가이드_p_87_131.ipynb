{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs4E4nEXQhr3k1HtZEwvtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3zero69/-/blob/main/0930_%ED%8C%8C%EC%9D%B4%EC%8D%AC%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C_p_87_131.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#CHAPTER 02 사이킷런으로 시작하는 머신러닝\n",
        " \n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "4Yp8kIGiU7JF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 사이킷런 소개와 특징\n",
        "* 사이킷런: 파이썬 기반의 머신러닝을 위한 가장 쉽고 효율적인 개발 라이브러리\n",
        " - 텐서플로, 케라스 등 딥러닝 전문 라이브러리 존재\n",
        " - 사이킷런은 파이썬 ML 라이브러리\n",
        "* 사이킷런의 특징\n",
        "  - 파이썬 기반의 다른 머신러닝 패키지도 사이킷런 스타일의 API를 지향할 정도로 쉽고 가장 파이썬 스러운 API 제공\n",
        "  - 머신러닝을 위한 매우 다양한 알고리즘 개발을 위한 편리한 프레임워크와 API 제공\n",
        "  - 오랜 기간 실전 환경에서 검증, 매우 많은 환경에서 사용되는 성숙한 라이브러리"
      ],
      "metadata": {
        "id": "IvHaaFbQVLuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__) # 사이킷런 버전 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5PhkFcKU8HB",
        "outputId": "ebc289a5-ff1e-4152-ebd9-b0e89b8e0eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##02. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기"
      ],
      "metadata": {
        "id": "mf-clazQWFmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 머신러닝 모델: 붓꽃 데이터 세트로 붓꽃의 품종을 분류(Classification)\n",
        "  - 붓꽃 데이터세트 : 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피쳐(Feature)를 기반으로 품종 예측 "
      ],
      "metadata": {
        "id": "J303VqUYWNZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분류(Classification)\n",
        "- 대표적인 지도학습(Supervised Learning) 방법\n",
        "  - 지도학습: 학습을 위한 다양한 피쳐와 분류 결정값인 레이블(Label) 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측\n",
        "  - 명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식\n",
        "    - 학습 데이터 세트: 학습을 위해 주어진 데이터 세트\n",
        "    - 테스트 데이터 세트: 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트"
      ],
      "metadata": {
        "id": "SNXIrkHzWqVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런에서 사용할 모듈 임포트"
      ],
      "metadata": {
        "id": "LN56Ffr5aYYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris # 붓꽃 데이터 세트 생성\n",
        "from sklearn.tree import DecisionTreeClassifier # ML 알고리즘 : 의사결정트리(Decision Tree) 알고리즘\n",
        "from sklearn.model_selection import train_test_split # 데이터 세트를 학습 데이터와 테스트 데이터로 분리"
      ],
      "metadata": {
        "id": "kxBubvOgU75O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * 사이킷런 패키지 내의 모듈명은 skleran으로 시작하는 명명규칙\n",
        " - `sklearn.tree` : 사이킷런에서 자체적으로 제공하는 데이터 세트 생성 모듈\n",
        " *`sklearn.model_selection` : 학습 데이터와 검증 데이터, 예측 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임\n",
        "   - 하이퍼 파라미터: 머신러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 마라미터, 머신러닝 알고리즘의 성능 튜닝 가능\n"
      ],
      "metadata": {
        "id": "P-cuGnG2XX31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "붓꽃 데이터 세트 로드 후, 데이터 구조 분석 (피처들과 데이터 값 구성)"
      ],
      "metadata": {
        "id": "lJRSB0BDaWC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#붓꽃 데이터 세트 로딩\n",
        "iris = load_iris()\n",
        "\n",
        "#iris.data는 Iris 데이터 세트에서 feature 만으로 된 데이터를 numpy로 갖고 있음\n",
        "iris_data = iris.data\n",
        "\n",
        "#iris.target은 붓꽃 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 갖고 있음\n",
        "iris_label = iris.target\n",
        "print('iris target 값: ', iris_label)\n",
        "print('iris target 명: ', iris.target_names)\n",
        "\n",
        "#붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환\n",
        "iris_df = pd.DataFrame(data=iris_data, columns = iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "vsM2q3IuZdiR",
        "outputId": "1c417d15-1cf9-4216-b99a-b00ffab7d821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris target 값:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "iris target 명:  ['setosa' 'versicolor' 'virginica']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f4fec31-2791-4b2c-a401-f57b6e2285cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f4fec31-2791-4b2c-a401-f57b6e2285cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f4fec31-2791-4b2c-a401-f57b6e2285cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f4fec31-2791-4b2c-a401-f57b6e2285cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">  * 피처 : sepal length, sepal width, petal length, petal width\n",
        " * 레이블 : 0,1,2 세가지 값( 0이 setosa, 1이 versicolor, 2가 virginica )"
      ],
      "metadata": {
        "id": "pltguafdZTh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습용 데이터와 테스트용 데이터 분리\n",
        "\n"
      ],
      "metadata": {
        "id": "FyUfIDM-acLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "LiDCUNFBaLHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> \n",
        "* `train_test_split()` : 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 분할\n",
        " - 예) test_size = 0.2 ; 전체 데이터 중 테스트 데이트 20%, 학습 데이터 80% 로 데이터 분할\n",
        " - 파라미터\n",
        "   - iris_data : 피처 데이터 세트\n",
        "   - iris_label: 레이블 데이터 세트\n",
        "   - test_size=0.2 : 전체 데이터 세트 중 테스트 데이터 세트의 비율\n",
        "   - random_state : 호출 시 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값 ( 미지정시, 수행할 때마다 다른 학습/테스트용 데이터를 만들 수 있음)\n",
        "\n",
        ">   학습용 피처 데이터 세트를 X_train으로, 테스트용 피처 데이터 세트를 X_test로, 학습용 레이블 데이터 세트를 y_train으로, 테스트용 레이블 데이터 세트를 y_test로 반환[링크 텍스트"
      ],
      "metadata": {
        "id": "wjtNuiifagqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "의사결정 트리(머신러닝 분류 알고리즘)를 이용해 학습과 예측 수행"
      ],
      "metadata": {
        "id": "Msp4Gs1mcjWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DecisionTreeClassfier를 객체로 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "#학습 수행\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KeE6obRcwV1",
        "outputId": "bce99ed0-3ecb-4fef-9527-84cf921ef4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(random_state=11)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 학습 함수 : `fit(학습용 피처 데이터 속성, 결정값 데이터 세트)`"
      ],
      "metadata": {
        "id": "UbG3PtX9do-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
        "pred = dt_clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "_yuIRjx6dZGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 예측 함수: `predict(테스트용 피처 데이터 세트)`\n",
        "- 학습데이터가 아닌 다른 데이터를 이용해야 함 (테스트 데이터 세트 이용)"
      ],
      "metadata": {
        "id": "8GbTruTpcrBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측 성능 평가 - 정확도 측정"
      ],
      "metadata": {
        "id": "WYIIimIndH4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjVL-6bHdHim",
        "outputId": "cf00b295-cfd8-45fb-d4a2-d67df902a48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 정확도 측정 \n",
        " - 정확도: 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표\n",
        "\n",
        "> 정확도 측정 함수 : `accuracy_score(실제 레이블 데이터 세트, 예측 레이블 데이터 세트)`"
      ],
      "metadata": {
        "id": "LjqbLYoveNhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*정리 *\n",
        "1. **데이터 세트 분리**: 데이터를 학습 데이터와 테스트 데이터로 분리\n",
        "2. **모델 학습**: 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습\n",
        "3. **예측 수행**: 학습된 ML 모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측\n",
        "4. **평가**: 예측된 결과값과 테스트 데이터의 실제 결과값을 비교해 ML 모델 성능을 평가"
      ],
      "metadata": {
        "id": "LAFVlARyeivT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 사이킷런의 기반 프레임워크 익히기\n",
        "\n",
        "* Estimator 클래스\n",
        " - 분류 알고리즘 구현 클래스 : Classifier\n",
        " - 회귀 알고리즘 구현 클래스 : Regressor\n",
        " \n",
        "1. evaluatio 함수 *cross_val_score()*, 하이퍼 파라미터 튜닝을 지원하는 클래스 *GridSearchCV* 의 경우 Estimator를 인자로 받음\n",
        "2. 인자로 받은 Estimator에 대해서 cross_val_score(), GridSearchCV.fit() 함수 내에서 Estimator의 fit()과 predict()를 호출해서 평가를 하거나 하이퍼 파라미터 튜닝 수행\n",
        "\n"
      ],
      "metadata": {
        "id": "T-uuYQNtfAXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사이킷런의 주요 모듈\n",
        "교재 p.94-95"
      ],
      "metadata": {
        "id": "wJqpTlPDipxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###내장된 예제 데이터 세트\n",
        "교재 p.96-97\n",
        "* 분류나 회귀를 연습하기 위한 \n",
        " - 딕셔너리 형태\n",
        " - 키 \n",
        "   - data : 데이터 세트 - 넘파이 배열 타입\n",
        "   - target : 레이블 값(분류)/ 숫자 결과값(회귀) 데이터 세트 - 넘파이 배열 타입\n",
        "   - target_name : 개별 레이블의 이름 - 넘파이 배열 또는 파이썬 리스트 타입\n",
        "   - featur_names : 피처의 이름 - 넘파이 배열 또는 파이썬 리스트 타입\n",
        "   - DESCR : 데이터 세트에 대한 설명과 각 피처의 설명 - 스트링 타입\n",
        "* 분류나 클러스터링을 위해 표본 데이터로 생성될 수 있는 데이터 세트\n"
      ],
      "metadata": {
        "id": "1OvQ0CJli3mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cf. 피처의 데이터 값을 반환받기 위해서는 내장 데이터 세트 API를 호출한 뒤에 그 key 값을 지정 "
      ],
      "metadata": {
        "id": "OugyIT3QjBUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "붓꽃 데이터 세트 생성"
      ],
      "metadata": {
        "id": "M4_s7cXfkt1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "iris_data = load_iris() #  데이터 세트에 내장되어 있는 대부분의 데이터 세트는 딕셔너리 형태의 값을 반환"
      ],
      "metadata": {
        "id": "y_i4iIcMjEBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> API 반환 결과; sklearn.utils.Bunch 클래스\n",
        " * Bunch 클래스는 파이썬 딕셔너리 자료형과 유사\n"
      ],
      "metadata": {
        "id": "ApQRuRCHk9aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = iris_data.keys() # 딕셔너리 형태의 키값 확인\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRozrA07lXlU",
        "outputId": "ff423fa7-6bb7-4805-8a2c-693a1d6e6bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "피처 데이터 값 추출 \n",
        ": `데이터세트.data / 데이터세트['data']`"
      ],
      "metadata": {
        "id": "YR5NxvJAmGCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load_iris() 가 반환하는 객체의 키인 feature_names, target_name, data, target 이 가리키는 값 출력"
      ],
      "metadata": {
        "id": "cIRg4hR8mfG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n feature_names 의 type:', type(iris_data.feature_names))\n",
        "print('feature_names 의 shape:', len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "print('\\n target_names의 type:', type(iris_data.target_names))\n",
        "print('target_names의 shape:', len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data의 type:', type(iris_data.data))\n",
        "print('data의 shape:', iris_data.data.shape)\n",
        "print(iris_data.data)\n",
        "\n",
        "print('\\n target의 type:', type(iris_data.target))\n",
        "print('target_namesdml shape:', iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytlhVjHKlgML",
        "outputId": "cdbbb9ba-3ca9-4b30-f44f-a40c358112e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " feature_names 의 type: <class 'list'>\n",
            "feature_names 의 shape: 4\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\n",
            " target_names의 type: <class 'numpy.ndarray'>\n",
            "target_names의 shape: 3\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "\n",
            " data의 type: <class 'numpy.ndarray'>\n",
            "data의 shape: (150, 4)\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "\n",
            " target의 type: <class 'numpy.ndarray'>\n",
            "target_namesdml shape: (150,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. Model Selection 모듈 소개\n",
        "* model_selection 모듈\n",
        " - 학습 데이터와 테스트 데이터 세트를 분리, 교차 검증 분할 및 평가, 그리고 Estimatior의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스 제공"
      ],
      "metadata": {
        "id": "rC-QKM_jm30E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 학습/테스트 데이터 세트 분리 : **train_test_split()** \n",
        "* 파라미터\n",
        " - 첫번째 파라미터 피처 데이터 세트, 두번째 파라미터 레이블 데이터 세트\n",
        " - 선택적 파라미터\n",
        "   * test_size : 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가를 결정함 ( 디폴트는 0.25 )\n",
        "   * train_size : 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것이나 결정, test_size parameter를 통상적으로 사용하기 때문에 잘 사용하지 않음\n",
        "   * shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지 결정, 디폴트는 True, 데이터를 분산시켜서 좀 더 효율적인 학습 및 테스트 데이터 세트를 만드는 데 사용\n",
        "   * random_state :호출할 때마다 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값\n",
        "* 반환값: 튜플 형태 \n",
        " - 순차적으로 학습용 데이터 피처 데이터 세트, \n",
        " - 테스트용 데이터의 피처 데이터 세트,\n",
        " - 학습용 데이터의 레이블 데이터 세트, \n",
        " - 테스트용 데이터의 레이블 데이터 세트가 반환"
      ],
      "metadata": {
        "id": "YNPY9ZwlnLoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "붓꽃 데이터 세트 학습"
      ],
      "metadata": {
        "id": "GXv6rE8woxty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size = 0.3, random_state = 121)\n"
      ],
      "metadata": {
        "id": "eZbSRPrdnR53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습데이터 기반으로 DecisionTreeClassifier 학습 후 해당 모델을 이용해 예측 정확도 측정"
      ],
      "metadata": {
        "id": "9CfPvSGHnRqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy9FuFSIom_n",
        "outputId": "37cb5ad0-12e4-4471-d509-d107f4fb1699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 교차 검증\n",
        "* 배경\n",
        " * 별도의 테스트용 데이터를 이용하는 방법 역시 과적합에 취약함\n",
        "   - 과적합(Overfitting) : 모델이 학습 데이터에만 과도하게 최적화 되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것\n",
        "  * 고정된 학습 데이터와 테스트 데이터로 평가를 하다 보면 테스트 데이터에만 최적의 성능을 발휘할 수 있도록 모델을 유도하는 경향이 생김\n",
        "  * 해당 테스트 데이터에만 과적합 되는 학습 모델의 생성으로 다른 테스트용 데이터가 들어올 경우에는 성능이 저하\n",
        "\n",
        "* **교차검증** : 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것\n",
        " - 각 세트에서 수행한 평가 결과에 따라 하이퍼 파라미터 튜닝 등의 모델 최적화를 더 손쉽게 가능\n",
        " \n"
      ],
      "metadata": {
        "id": "rodBS9fgo51p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K 폴드 교차 검증**\n",
        ": K 개의 데이터 폴드 세트를 만들어 K번 만큼 각 폴트 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
        "\n",
        "* K = 5 인 경우 _ 5개의 폴드된 데이터 세트를 학습과 검증을 위한 데이터 세트로 변경하면서 5번 평가를 수행한 뒤, 이 5개의 평가를 평균한 결과를 가지고 예측 성능을 평가\n",
        "1. 데이터 세트 K등분 나누기 \n",
        "2. 학습 데이터 세트에서 학습 수행/검증 데이터 세트에서 평가를 수행 : 첫번째 반복에서는 처음부터 4개 등분을 학습 데이터 세트, 마지막 5번째 등분 하나를 검증 데이터 세트로 설정, \n",
        "3. 두번째 ~ K번째 반복에서 비슷한 학습과 평가 작업 수행 (단, 학습 데이터와 검증 데이터를 변경 : 검증데이터를 하나씩 당겨옴) \n",
        "4. K 개의 예측 평가를 구한 후, 이를 평균하여 K 폴드 평가 결과로 반영\n",
        "\n"
      ],
      "metadata": {
        "id": "m233vyvDpI_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "df_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "#5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기: ', features.shape[0]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5RgmpVdtHtO",
        "outputId": "2d7e6aac-ab7d-46ba-e0a0-6d0fd0320db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트 크기:  150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">  * KFold 객체는 split()을 호출하면 학습용/검증용 데이터로 분할할 수 있는 인덱스를 반환함\n",
        "  - 실제로 학습용/검증용 데이터 추출은 반환된 인덱스를 기반으로 개발 코드에서 직접 수행해야함"
      ],
      "metadata": {
        "id": "heNJoJ9VhB1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KFold 객체의 split()을 호출해 교차 검증 수행 시마다 학습과 검증을 반복해 예측 정확도 측정"
      ],
      "metadata": {
        "id": "tf8YFJpHhKtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 0\n",
        "\n",
        "#KFold 객체의 split()를 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):  \n",
        "\n",
        "  # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "\n",
        "  #반복 시마다 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred),4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration 별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bw4BjZhtNJ4",
        "outputId": "4371e694-e00e-48a0-df0e-6a1be8f9d32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도: 0.8333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.9200000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stratified K 폴드** : 불균형한 (imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식\n",
        "- K 폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결\n",
        "- Stratified K 폴드는 원본 데이텅의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습과 검증 데이터 세트를 분배함"
      ],
      "metadata": {
        "id": "gIdpUE_dpOOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns = iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UbinDcuuyRk",
        "outputId": "640ba61e-2e00-479d-e805-ad6d1cf6d928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    50\n",
              "1    50\n",
              "2    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포 : \\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포 : \\n', label_test.value_counts())\n",
        "  iris_df['label'].value_counts()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsKZumStu3dd",
        "outputId": "4b57d007-d63f-41f9-acdf-06790623a4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포 : \n",
            " 1    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포 : \n",
            " 0    50\n",
            "2    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포 : \n",
            " 0    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 : \n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 교차 검증 시마다 3개의 폴드 세트로 만들어지는 학습 레이블과 검증 레이블이 완전히 다른 값으로 추출\n",
        " \n",
        "  - ex. 학습 레이블은 1,2 밖에 없으므로 0의 경우는 전혀 학습하지 못하므로 예측하지 못함"
      ],
      "metadata": {
        "id": "BrwxlhVAu7TO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " * StratifiedKFold 를 사용하는 방법은 KFold를 사용하는 방법과 거의 비슷\n",
        " * 단 하나 큰 차이는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 split() 메서드에 인자로 피처 데이터 세트뿐만 아니라 레이블 데이터 세트도 반드시 필요"
      ],
      "metadata": {
        "id": "N_Ym8ltmu_Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter +=1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHzIoOmPvFI3",
        "outputId": "a49599f0-00d2-439b-867e-800233571bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "0    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    17\n",
            "1    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "0    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    17\n",
            "2    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "1    33\n",
            "2    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "2    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "#StratifiedKFold의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "  #split()으로 반환도니 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train,y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "\n",
        "  #반복시마다 정확도 측정\n",
        "  n_iter += 1\n",
        "  accuracy = np.round(accuracy_score(y_test,pred),4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "  #교차 검증별 정확도 및 평균 정확도 계산\n",
        "  print('\\n## 교차 검증별 정확도 : ', np.round(cv_accuracy,4))\n",
        "  print('## 평균 검증 정확도 :', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj9hV_6FvHH1",
        "outputId": "40c757bc-13dc-4340-9cf2-7c9f0cc940cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "## 교차 검증별 정확도 :  [0.98]\n",
            "## 평균 검증 정확도 : 0.98\n",
            "\n",
            "#2 교차 검증 정확도: 0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#2 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "## 교차 검증별 정확도 :  [0.98 0.94]\n",
            "## 평균 검증 정확도 : 0.96\n",
            "\n",
            "#3 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#3 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도 : 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**교차 검증을 보다 간편하게 - cross_val_score()**\n",
        "\n",
        "\n",
        "1.   폴드 세트 설정\n",
        "2.   for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스 추출\n",
        "3. 반복적으로 학습과 예측 수행하고 예측 성능 반환\n",
        "\n",
        "     `corss_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch=2*n_jobs')`\n",
        "- 주요 파라미터\n",
        "  - estimator: 사이킷런의 분류 알고리즘 세트(Classifier / Regressor)\n",
        "  - X: 피처 데이터 세트\n",
        "  - y: 레이블 데이터 세트\n",
        "  - scoring: 예측 성능 평가 지표\n",
        "  - cv: 교차 검증 폴드 수\n",
        "* 반환값: scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
        "* 학습/테스트 세트 분할 방식\n",
        " - classifier 입력시, Stratified K 폴드 방식으로 레이블값의 분포에 따라 분할\n",
        " - regressor 입력시, K폴드 방식으로 분할 (Stratified 방식 분할 불가)\n"
      ],
      "metadata": {
        "id": "-x-ZNP2vpXN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import method from module\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score , cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# 데이터셋 및 DecisionTreeClassifier 생성\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# Feature 데이터셋과 Label 데이터셋 분리\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy) , 교차 검증 세트는 3개 \n",
        "scores = cross_val_score(dt_clf , data , label , scoring = 'accuracy',cv = 3)\n",
        "print('교차 검증별 정확도:',np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ulMuBj8uxxO",
        "outputId": "ef88da6b-9d46-4660-c5ac-9b405a8ebfc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "평균 검증 정확도: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에\n",
        ": 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안\n",
        "* \n"
      ],
      "metadata": {
        "id": "ZCV-4_6-pcHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습데이타와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "# parameter 들을 dictionary 형태로 설정\n",
        "parameters = {'max_depth':[1,2,3],\n",
        "              'min_samples_split':[2,3]}"
      ],
      "metadata": {
        "id": "uI8VP1wciSND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터들을 3개의 폴드로 나누어 테스트 수행\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True ) # refit=True 가 default / True 이면 가장 좋은 파라미터 설정으로 재학습   \n",
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "DNkqYytpin2e",
        "outputId": "1dcdb611-80c4-439a-935b-84390883ff8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     params  mean_test_score  rank_test_score  \\\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
              "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
              "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
              "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
              "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
              "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  \n",
              "0              0.700                0.7               0.70  \n",
              "1              0.700                0.7               0.70  \n",
              "2              0.925                1.0               0.95  \n",
              "3              0.925                1.0               0.95  \n",
              "4              0.975                1.0               0.95  \n",
              "5              0.975                1.0               0.95  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40af7c80-61bf-44ec-9a3a-cdb65078ba0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40af7c80-61bf-44ec-9a3a-cdb65078ba0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40af7c80-61bf-44ec-9a3a-cdb65078ba0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40af7c80-61bf-44ec-9a3a-cdb65078ba0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * pandas 칼럼에는 수행할 때마다 적용된 개별 하이퍼 파라미터값을 나타냄\n",
        "* rank_test_score : 하이퍼 파라미터별로 성능이 좋은 score 순위를 나타냄 (1이 가장 뛰어난 순위, 최적의 하이퍼 파라미터)\n",
        "* mean_test_score : 개별 하이퍼 파라미터별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평균값\n"
      ],
      "metadata": {
        "id": "h9Md7SacjVQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best_params_ : 최고 성능을 나타낸 하이퍼 파라미터 값\n",
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "\n",
        "# best_score_ : 최고 성능을 나타낼 때, 모델의 성능 평가의 결과 값\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1MECmUhj3Xm",
        "outputId": "338936af-6017-4a0e-ad90-27664a1de9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# refit = True이면 최적 성능을 나타내는 하이퍼 파라미터로 Estimator를 학습해 best_estimator_에 저장\n",
        "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2h4gGhoj39z",
        "outputId": "2b66d4ea-7258-4a2b-ef34-695ae33146fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 세트 정확도: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05. 데이터 전처리\n",
        "* 결손값 (NaN, NULL 값) 허용 안됨\n",
        "  - Null 값은 고정된 다른 값으로 변환해야 함\n",
        "     - 피처 값중 Null값이 얼마 되지 않는 경우, 피처의 평균값으로 간단히 대체\n",
        "     - Null 값이 대부분이라면, 해당 피처는 드롭하는 것이 좋음\n",
        "     - Null 값이 일정 수준 이상 되는 경우(중요도가 높은 피처, Null 값을 단순히 피처의 평균값으로 대체할 경우 예측 왜곡이 심하다면), 업무 로직을 검토해 정밀한 대체값을 선정해야 함\n",
        "* 문자열 값을 입력값으로 허용하지 않음\n",
        "  - 모든 문자열은 인코딩 되어 숫자형으로 변환해야 함\n",
        "  - 카테고리형 피처: 코드값으로 표현\n",
        "  - 텍스트형 피처: 피처 벡터화 등의 기법으로 벡터화하거나 불필요한 피처의 경우 삭제\n",
        "    - 예) 주민번호, 단순 문자열 아이디의 경우 인코딩하지 않고 삭제"
      ],
      "metadata": {
        "id": "VHEKaHVqpo2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 인코딩"
      ],
      "metadata": {
        "id": "9tMz_Qyfps5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **레이블 인코딩**\n",
        ": 카테고리 피처 -> 코드형 숫자 값으로 변환\n",
        "  - 주의 : '01','02' 와 같은 코드값 역시 문자열이므로 1,2 와 같은 숫자형으로 변환해야 함\n"
      ],
      "metadata": {
        "id": "3tvMmc2ipvVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "#LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값 : ', labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l6VH-eCn6YM",
        "outputId": "291d18fe-efc4-4e36-fb0d-6d2d8ff74402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 변환값 :  [0 1 4 5 3 3 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코딩 클래스 :', encoder.classes_)\n",
        "# classes_속성값 :어떤 값으로 인코딩 됐는지 확인 0부터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p6nSr90oeIS",
        "outputId": "828d2635-9413-475b-9031-c05c8de6a517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인코딩 클래스 : ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('디코딩 원본값 : ', encoder.inverse_transform([4,5,2,0,1,1,3,3]))\n",
        "# inverse_transform() : 인코딩된 값 다시 디코딩"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y6N606_ohWS",
        "outputId": "53fe56bc-87a5-4a67-c83d-8ec2ebb7fe42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "디코딩 원본값 :  ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 문제점 \n",
        "  - 일괄적인 숫자값으로 변환되면서 몇몇 ML 알고리즘에는 이를 적용할 경우 예측 성능이 떨어짐 (숫자값의 경우 크고 작음에 대한 특정이 작용하기 때문)\n",
        "  - 그러나, 숫자 변환값은 단순 코드이기 때문에 숫자값에 따른 순서나 중요도로 인식되어서는 안됨\n",
        "     -  회귀와 같은 ML 알고리즘에는 적용 x \n",
        "     - 트리 계열의 ML 알고리즘은 숫자의 특성을 반영하지 않으므로 적용 O"
      ],
      "metadata": {
        "id": "_l-UzWT_o0JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **원-핫 인코딩(One-Hot Encoding)**\n",
        ": 피처 값의 유형에 따라 새로운 피처를 추가해 고유값에 해당하는 칼럼에만 1을 표시, 나머지 칼럼에는 0 표시"
      ],
      "metadata": {
        "id": "ey8QkQIUpyUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "#먼저 숫자값으로 변환을 위해 LabelEncoder로 변환\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "\n",
        "#2차원 데이터로 변경\n",
        "labels = labels.reshape(-1,1)\n",
        "\n",
        "#원핫 인코딩을 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print('원 핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원 핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUk0YXNpppg9",
        "outputId": "35f74012-008f-4ab2-add5-3a2dbea91173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원 핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원 핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 판다스 원-핫 인코딩 지원 API : `.get_dummies()`\n",
        " - 사이킷런과 달리, 문자열 카테고리 값을 숫자형으로 변환할 필요 없이 바로 변환 가능"
      ],
      "metadata": {
        "id": "1gNkbXoipn0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "c5bEL1uopyAU",
        "outputId": "e6909ef2-c980-4fd1-e0f7-d25ae8536717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
              "0        1         0        0         0           0         0\n",
              "1        0         1        0         0           0         0\n",
              "2        0         0        0         0           1         0\n",
              "3        0         0        0         0           0         1\n",
              "4        0         0        0         1           0         0\n",
              "5        0         0        0         1           0         0\n",
              "6        0         0        1         0           0         0\n",
              "7        0         0        1         0           0         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a33418b-be3c-4233-8ac2-2d52cb8c4ccb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_TV</th>\n",
              "      <th>item_냉장고</th>\n",
              "      <th>item_믹서</th>\n",
              "      <th>item_선풍기</th>\n",
              "      <th>item_전자레인지</th>\n",
              "      <th>item_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a33418b-be3c-4233-8ac2-2d52cb8c4ccb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a33418b-be3c-4233-8ac2-2d52cb8c4ccb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a33418b-be3c-4233-8ac2-2d52cb8c4ccb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 피처 스케일링과 정규화 \n",
        ": 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "\n",
        "- **표준화 (Standardization)** : 데이터 피처 각각이 평균이 0, 분산이 1 인 가우시안 정규분포를 가진 값으로 변환하는 것\n",
        "\n",
        "- **정규화 (Normalization**) : 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 것\n",
        "  - 개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것\n",
        "  - "
      ],
      "metadata": {
        "id": "P7uTlSMPp4T3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StandardScaler**\n",
        ": 표준화 지원 클래스 \n",
        "- 가우시안 분포를 가질 수 있도록 데이터 변환"
      ],
      "metadata": {
        "id": "deZmDjU_p7Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "#붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns = iris.feature_names)\n",
        "\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgX-2fF7rAh7",
        "outputId": "52060530-c167-46cd-dd5a-528990b4268c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature 들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinMaxScaler**\n",
        ": 데이터값을 0과 1 사이의 범위 값으로 변환(음수 값은 -1에서 1로 변환)\n",
        "- 데이터 분포가 가우시안 분포가 아닌 경우에 적용"
      ],
      "metadata": {
        "id": "xxvv3xBip-_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "#transform()시 스케일 변환된 데이터 세트가 Numpy ndarray로 변환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature 들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CVUNT-9rKXG",
        "outputId": "03197171-8b9c-4f8d-812a-d4d2eced0f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature 들의 최솟값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "\n",
            "feature들의 최댓값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 학습 데이터와 테스트 데이터의 스케일링 변환시 유의점\n"
      ],
      "metadata": {
        "id": "xD-2tHJBqB-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**테스트 데이터에 fit()을 적용할 경우의 문제점**\n",
        "- 테스트 데이터에 다시 fit()을 적용하면 안되고, 학습 데이터로 이미 fit()이 적용된 Scaler 객체를 이용해 transform() 으로 변환해야 함"
      ],
      "metadata": {
        "id": "V0j0Z_Rbrkey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* fit_transform() 적용 시에도, 테스트 데이터에서는 절대 사용해서는 안됨\n",
        "\n"
      ],
      "metadata": {
        "id": "JYSDWrkGr9fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "#학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
        "#Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1,1)로 차원 변경\n",
        "train_array = np.arange(0,11).reshape(-1,1)\n",
        "test_array = np.arange(0,6).reshape(-1,1)\n",
        "\n",
        "#MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10 으로 설정\n",
        "scaler.fit(train_array)\n",
        "\n",
        "#1/10 scale로 train_array 데이터 변환함, 원본 10 -> 1로 변환됨\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터 :', np.round(train_array.reshape(-1),2))\n",
        "print('Scale된 train_array 데이터 :', np.round(train_scaled.reshape(-1),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXnefcIdrn4q",
        "outputId": "4618a50d-38c1-4ae6-ee96-b2d038f90b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 train_array 데이터 : [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터 : [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 데이터 세트 변환시, fit() 호출해 스케일링 기준 정보를 다시 적용한 뒤 transform() 을 수행"
      ],
      "metadata": {
        "id": "pg0hSUH4rucm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
        "scaler.fit(test_array)\n",
        "\n",
        "#1/5 scale로 test_array 데이터 변환함 원본 5 ->1로 변환\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "#test_array의 scale 변환 출력\n",
        "print('원본 test_array 데이터 : ', np.round(test_array.reshape(-1),2))\n",
        "print('Scale된 test_array 데이터 : ', np.round(test_scaled.reshape(-1),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnMOASVTr13k",
        "outputId": "073717a4-de6f-426c-ea79-2d48455b6713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 test_array 데이터 :  [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터 :  [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 학습 데이터와 테스트 데이터의 스켈링이 맞지 않음"
      ],
      "metadata": {
        "id": "I_FPVn1er5r-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "해결"
      ],
      "metadata": {
        "id": "JzX2QmeUs9VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터 :', np.round(train_array.reshape(-1),2))\n",
        "print('Scale된 train_array 데이터 :', np.round(train_scaled.reshape(-1),2))\n",
        "\n",
        "# fit() 호출하지 않고 transform()만으로 변환해야함\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터 : ', np.round(test_array.reshape(-1),2))\n",
        "print('Scale된 test_array 데이터 : ', np.round(test_scaled.reshape(-1),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IibQFoU1s-m-",
        "outputId": "59abce7f-6a05-41a9-fb84-4f8534029cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 train_array 데이터 : [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터 : [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "원본 test_array 데이터 :  [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터 :  [0.  0.1 0.2 0.3 0.4 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ 정리 \n",
        "1. 가능하다면 전체 데이터의 스케일링 변환 적용 후, 학습과 테스트 데이터로 분리\n",
        "2. (1)이 가능하지 않은 경우, 테스트 데이터 변환 시에는 fit()이나 fit_transform()이 아닌 학습데이터로 이미 fit()된 Scaler 객체를 이용해 transform()으로 변환"
      ],
      "metadata": {
        "id": "V1eaDhPsskCr"
      }
    }
  ]
}