{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFKKbyIjwdtmQFykNbR5pd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3zero69/-/blob/main/%ED%95%B8%EC%A6%88%EC%98%A8%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_CH7_%EC%95%99%EC%83%81%EB%B8%94%ED%95%99%EC%8A%B5%EA%B3%BC%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8_pg245_271.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. 앙상블 학습과 랜덤 포레스트"
      ],
      "metadata": {
        "id": "o0tMZn3a8Fd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **앙상블 학습** :  **앙상블** , 일련의 예측기(즉, 분류나 회귀모델)로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있음\n",
        "\n",
        "\n",
        " - **앙상블 방법** : 앙상블 학습 알고리즘\n",
        "    - 예)  **랜덤 포레스트** : 결정트리의 앙상블, 훈련 세트로부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련시킬 수 있음\n",
        "      - 예측을 하려면 모든 개별 트리의 예측을 구하면 됨\n",
        "      - 그런 다음 가장 많은 선택을 받은 클래스를 예측으로 삼음\n",
        "  - 가장 인기있는 앙상블 방법: **배깅, 부스팅, 스태킹**\n",
        "\n",
        "프로젝트의 마지막에 다다르면 흔히 앙상블 방법을 사용하여 이미 만든 여러 괜찮은 예측기를 연결하여 더 좋은 예측기를 만듦\n"
      ],
      "metadata": {
        "id": "0scTlg6Q8KIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 투표 기반 분류기\n",
        "\n"
      ],
      "metadata": {
        "id": "pwxk8XbB9dF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정확도가 80% 인 분류기 여러 개를 훈련 (로지스틱 회귀 분류기, 랜덤 포레스트 분류기, K-최근접 이웃 분류기 등)\n",
        "\n",
        "- 더 좋은 분류기를 만드는 매우 간단한 방법은 각 분류기의 예측을 모아 가장 많이 선택된 클래스를 예측하는 것\n",
        "  - 다수결 투표로 정해지는 분류기 - **직접 투표 분류기**\n",
        "  - 다수결 투표 분류기는 앙상블에 포함된 개별 분류기 중 가장 뛰어난 것보다 정확도가 더 높음\n",
        "\n",
        "- 각 분류기가 약한 학습기(랜덤 추측보다 약간 더 높은 성능을 내는 분류기) 이더라도 충분히 많고 다양하다면, 앙상블은 강한 학습기(높은 정확도를 내는 분류기) 가 될 수 있음"
      ],
      "metadata": {
        "id": "QskzBaQU-yYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 어떻게 ? \n",
        "  - 큰 수의 법칙 : 던진 횟수가 증가할수록 앞면이 나올 확률이 51% 에 가까워짐\n",
        "- 이와 비슷하게 51% 정확도(무작위 추측보다 조금 더 나은) 를 가진 1,000 개의 분류기로 앙상블 모델을 구축\n",
        "  - 가장 많은 클래스를 예측으로 삼으면 75% 정확도 기대 가능\n",
        "  - 물론 모든 분류기가 완벽히 독립적이고 오차에 상관관계가 없는 경우에 성립"
      ],
      "metadata": {
        "id": "_gFl3hRA_Jhv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI1QYQydrUgC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "X,y=make_moons(n_samples=500, noise=0.15)\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 여러 분류기를 조합한 투표 기반 분류기 (VotingClassifier) 훈련 코드\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "rnd_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='hard')\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "RE3gHe489-Us",
        "outputId": "832dca70-3ab6-4c8d-ae7b-45bdad74ad0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 분류기의 테스트셋 정확도 확인\n",
        "from sklearn.metrics import accuracy_score\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
        "\n",
        "  ## 투표 기반 분류기가 다른 분류기보다 성능이 조금 더 높음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bICHYrp9_w6",
        "outputId": "41be7450-d250-4ed7-8d9c-b0e90ce43823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.87\n",
            "RandomForestClassifier 0.98\n",
            "SVC 0.98\n",
            "VotingClassifier 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 분류기가 클래스의 확률을 예측할 수 있으면(predict_proba() 메서드), 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스 예측 가능 - 간접 투표\n",
        "\n",
        "확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 높음\n",
        "\n",
        "- voting = \"hard\" 를 voting = \"soft\" 로 바꾸고, 모든 분류기가 클래스의 확률을 추정할 수 있으면 됨\n",
        "- SVC : probabilty = True 지정"
      ],
      "metadata": {
        "id": "uBf-2ZMWArNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 배깅과 페이스팅"
      ],
      "metadata": {
        "id": "i0t1bBcR-Cim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다양한 분류기를 만드는 한가지 방법 : 각기 다른 훈련 알고리즘을 사용하는 것\n",
        "\n",
        "또 다른 방법 : 같은 알고리즘을 사용하고, 훈련 세트의 서브셋을 무작위로 구성하여 분류기를 각기 다르게 학습\n",
        "\n",
        "* 배깅 : 훈련 세트에서 중복을 허용하여 샘플링\n",
        "* 페이스팅 : 중복을 허용하지 않고 샘플링\n",
        "  - 배깅과 페이스팅에서는 같은 훈련 샘플을 여러 개의 예측기에 걸쳐 사용 가능\n",
        "  - 배깅만 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링 가능"
      ],
      "metadata": {
        "id": "fDggJWYiBeDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모든 예측기가 훈련을 마치면 앙상블은 모든 예측기의 예측을 모다 새로운 샘플에 대한 예측을 만듦\n",
        "  - 수집 함수: 전형적으로 분류일때는 **통계적 최빈값** 이고, 회귀에 대해서는 평균을 계산\n",
        "\n",
        "- 개별 예측기는 원본 훈련 세트로 훈련시킨 것보다 훨씬 크게 편향되어 있지만, 수집 함수를 통과하면 편향과 분산이 모두 감소\n",
        "\n",
        "- 앙상블 결과는 원본 데이터셋으로 하나의 예측기를 훈련시킬 때와 비교해 편향은 비슷하지만 분산은 줄어듦"
      ],
      "metadata": {
        "id": "Al1aL3QWB-rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 사이킷런의 배깅과 페이스팅"
      ],
      "metadata": {
        "id": "AehtqCu4CeKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 결정 트리 분류기 500개의 앙상블 훈련 코드\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1)    \n",
        "# 각 분류기는 훈련 세트에서 중복을 허용하여 무작위로 선택된 100개의 샘플로 훈련 (배깅의 경우)\n",
        "# 페이스팅 사용시, bootstrap = False 지정\n",
        "# n_jobs : 사이킷런이 훈련과 예측에 사용할 CPU 코어 수 (-1 : 가용한 모든 코어 사용)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "ACq1r6kQ-Dzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블의 예측이 결정 트리 하나의 예측보다 일반화가 훨씬 잘됨 \n",
        "\n",
        " 앙상블은 비슷한 편향에서 더 작은 분산을 만듦(오차 수 거의 비슷, 결정 경계 덜 불규칙)"
      ],
      "metadata": {
        "id": "fkxeQnkYDiD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 oob 평가"
      ],
      "metadata": {
        "id": "pcZj4c1YDek7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "배깅 사용시, 어떤 샘플은 한 예측기를 위해 여러번 샘플링되고 어떤 것은 전혀 선택되지 않을 수 있음\n",
        "  - BaggingClassifier 는 기본값으로 중복을 허용하여 훈련 세트의 크기만큼인 m 개의 샘플을 선택\n",
        "  - 이는 평균적으로 각 예측기에 훈련 샘플의 63% 정도만 샘플링 된다는 것을 의미\n",
        "\n",
        "선택되지 않은 훈련 샘플의 나머지 73% 를 obb 샘플 이라고 부름 (예측마다 남겨진 37% 는 모두 다름)\n",
        "\n",
        "- 예측기 훈련 동안에는 obb 샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob 샘플을 사용해 평가 가능\n",
        "  - 앙상블의 평가는 각 예측기의 oob 평가를 평균하여 얻음"
      ],
      "metadata": {
        "id": "XWW5mVWEitnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 훈련이 끝나고 자동으로 oob 평가 수행 (oob_score = True)\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    bootstrap=True, n_jobs=-1, oob_score=True)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_  ## 테스트 세트에서 약 0.9725 의 정확도를 얻을 것으로 보임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4jrpOJx-FNd",
        "outputId": "4ebdfbc0-799b-459d-bb8a-03713db74973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9725"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred  ## 실제로 그러함 (비슷하군)"
      ],
      "metadata": {
        "id": "EjgrE0C9-Gu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oob 샘플에 대한 결정 함수의 값 확인\n",
        "bag_clf.oob_decision_function_ "
      ],
      "metadata": {
        "id": "1_1t6Vdw-IFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 랜덤 패치와 랜덤 서브스페이스"
      ],
      "metadata": {
        "id": "gaEzgbTF-J5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\tBaggingClassifier\n",
        "-\tMax_features\n",
        "-\tBootstrap_features \n",
        "-\tMax_samples, bootstrap 과 동일, 샘플이 아닌 특성이 대한 샘플링\n",
        "-\t각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련\n",
        "-\t매우 고차원의 데이터셋을 다룰 때 \n",
        " \n",
        "\t랜덤 패치 방식 : 훈련 특성과 샘플을 모두 샘플링 하는 것\n",
        "-\t랜덤 서브 스페이스방식 : 훈련 샘플을 모두 사용하고 특성은 샘플링하는 것\n"
      ],
      "metadata": {
        "id": "DHTL0GTAkfjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.4 랜덤 포레스트"
      ],
      "metadata": {
        "id": "3U2CMYGw-Mer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트 : 일반적으로 배깅 방법(또는 페이스팅) 을 적용한 결정 트리 앙상블\n",
        "\n"
      ],
      "metadata": {
        "id": "yIKJXkGmFLso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 랜덤 포레스트 훈련 \n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1) # 500 개 트리로 이루어진 랜덤 포레스트 분류기를 여러 CPU 코어에서 훈련\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "0211LplO-Np_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입함 \n",
        "\n",
        "이는 결국 트리를 더욱 다양하게 만들고 편향을 손해보는 대신 분산을 낮춤 (훌륭한 모델)"
      ],
      "metadata": {
        "id": "6QLvIVgdFjb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
        "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
      ],
      "metadata": {
        "id": "-OuSMoLg-PIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4.1 엑스트라 트리"
      ],
      "metadata": {
        "id": "sK8CG_U-F0Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트\n",
        "-\t트리를 만들 때 각 노드는 무작위로 특성의 서브셋을 만들어 분할에 사용\n",
        "-\t트리를 더욱 무작위로 만들기 위해 최적의 임곗값을 찾는 대신 후보 특성을 사용해 무작위로 분할한 다음 그 중에서 최상의 분할을 선택\n",
        "\n",
        "**익스트림 랜덤 트리 앙상블 (엑스트라 트리)** : 극단적으로 무작위한 트리의 랜덤 포레스트\n",
        "-\t편향이 늘어나지만 대신 분산을 낮춤\n",
        "-\t모든 노드에서 특성마다 가장 최적의 임곗값을 찾는 것이 트리 알고리즘에서 가장 시간이 많이 소요되는 작업 중 하나이므로 일반적인 랜덤 포레스트보다 엑스트라가 훨씬 빠름\n"
      ],
      "metadata": {
        "id": "MxJTrPujknpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4.2 특성 중요도"
      ],
      "metadata": {
        "id": "P9oO9FlJF3eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트 \n",
        "-\t특성의 상대적 중요도를 측정하기 쉬움\n",
        "-\t어떤 특성을 사용한 노드가 (모든 트리에 걸쳐서) 평균적으로 불순도를 얼마나 감소시키는지 확인하여 특성의 중요도를 측정\n",
        "\t가중치 평균이며 각 노드의 가중치는 연관된 훈련 샘플 수와 같음\n",
        "\n",
        "\n",
        "랜덤 포레스트는 특히 특성을 선택 해야할 때 어떤 특성이 중요한지 빠르게 확인 할 수 있어 매우 편리함\n"
      ],
      "metadata": {
        "id": "inkAfGdSkuP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "  print(name, score)\n",
        "  \n",
        "## 가장 중요한 특성은 꽃잎의 길이(44%) 와 너비(42%) 이고, 꽃받침의 길이와 너비는 비교적 덜 중요해 보임"
      ],
      "metadata": {
        "id": "I3Ri3xVS-QYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5 부스팅"
      ],
      "metadata": {
        "id": "ejPkFS38-RoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **부스팅** : 약한 학습기를 여러개 연결하여 강한 학습기를 만드는 앙상블 방법\n",
        "\n",
        " - 앞의 모델을 보완해나가면서 일련의 예측기를 학습\n",
        "  - 에이다부스트 \n",
        "  - 그레이디언트 부스트"
      ],
      "metadata": {
        "id": "cGs676QpEMsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5.1 에이다부스트"
      ],
      "metadata": {
        "id": "h4XHz0whEJ7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "osUSMXpp-Sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7.5.2 그레이디언트 부스팅"
      ],
      "metadata": {
        "id": "084l93w4Ei6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeRegressor를 훈련 세트에 학습\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg1.fit(X, y)"
      ],
      "metadata": {
        "id": "LXR21z8q-UdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 예측기에서 생긴 잔여 오차에 두 번째 DecisionTreeRegressor 훈련\n",
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "metadata": {
        "id": "5Lbu9Ce_-Vxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 번째 예측기가 만든 잔여 오차에 세 번째 회귀 모델 훈련\n",
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "metadata": {
        "id": "YU74V4s_-XHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 샘플에 대한 예측을 만들려면 모든 트리의 예측을 더하면 됨\n",
        "y_pred = sum(tree.predict(X_new)) for tree in (tree_reg1, tree_reg2, tree_reg3)"
      ],
      "metadata": {
        "id": "mN7S0YoTEvH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
        "gbrt.fit(X,y)"
      ],
      "metadata": {
        "id": "JF2Usmxc-Z0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors)+1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yDT3wlcO-cSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1,120):\n",
        "  gbrt.n_estimators = n_estimators\n",
        "  gbrt.fit(X_train, y_train)\n",
        "  y_pred = gbrt.predict(X_val)\n",
        "  val_error = mean_squared_error(y_val, y_pred)\n",
        "  if val_error < min_val_error:\n",
        "    min_val_error = val_error\n",
        "    error_going_up = 0\n",
        "  else:\n",
        "    error_going_up += 1\n",
        "    if error_going_up == 5:\n",
        "      break    # 조기 종료"
      ],
      "metadata": {
        "id": "ZgthAwit-eLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "     \n",
        "\n",
        "# 자동 조기 종료와 같은 여러 좋은 기능도 제공\n",
        "xgb_reg.fit(X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "     "
      ],
      "metadata": {
        "id": "KrArtbdA-foQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6 스태킹"
      ],
      "metadata": {
        "id": "50TGk7d1-gzb"
      }
    }
  ]
}